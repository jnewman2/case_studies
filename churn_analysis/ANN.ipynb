{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ca0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd66e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c6950",
   "metadata": {},
   "source": [
    "## Read in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dab0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.load(\"data/train_binary_data.npz\")\n",
    "validation_dataset = np.load(\"data/validation_binary_data.npz\")\n",
    "test_dataset = np.load(\"data/test_binary_data.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd95129",
   "metadata": {},
   "source": [
    "# Create Pytorch Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34b159f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, transform=None, target_transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.X = self.X.astype(\"float32\")\n",
    "        self.y = self.y.astype(\"float32\")\n",
    "        self.y = np.reshape(self.y, (len(self.y), -1))\n",
    "        \n",
    "    def  __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample, target = self.X[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            self.transform(sample)\n",
    "            self.target_transform(target)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8eafa479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = NumpyDataset(train_dataset['x'], train_dataset['y'])\n",
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3c1b7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = NumpyDataset(validation_dataset['x'], validation_dataset['y'])\n",
    "validation_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59cfc75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = NumpyDataset(test_dataset['x'], test_dataset['y'])\n",
    "test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dedaab",
   "metadata": {},
   "source": [
    "## Model Arch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe505b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(torch.nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(n_features, out_features=6)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(6, out_features=6)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(6, out_features=1)\n",
    "        torch.nn.init.xavier_normal(self.fc3.weight)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa953e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32,\n",
    "                            shuffle=True)\n",
    "validation_dl = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=32,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9abecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d541ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d72040ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jnewm\\AppData\\Local\\Temp\\ipykernel_23392\\745468581.py:14: FutureWarning: `nn.init.xavier_normal` is now deprecated in favor of `nn.init.xavier_normal_`.\n",
      "  torch.nn.init.xavier_normal(self.fc3.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ANNModel(\n",
       "  (fc1): Linear(in_features=13, out_features=6, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (fc2): Linear(in_features=6, out_features=6, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (fc3): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ANNModel(train_dataset.X.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c7923b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7ed7cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.46130 | Train Acc: 80.045\n",
      "\tEpoch 1 | Validation Loss: 0.4165504276752472 | Validation Acc: 82.220\n",
      "Epoch 002: | Train Loss: 0.37647 | Train Acc: 85.180\n",
      "\tEpoch 2 | Validation Loss: 0.36576306104660034 | Validation Acc: 84.800\n",
      "Epoch 003: | Train Loss: 0.35814 | Train Acc: 85.640\n",
      "\tEpoch 3 | Validation Loss: 0.36493451744318006 | Validation Acc: 85.060\n",
      "Epoch 004: | Train Loss: 0.34631 | Train Acc: 86.275\n",
      "\tEpoch 4 | Validation Loss: 0.3589263278245926 | Validation Acc: 85.040\n",
      "Epoch 005: | Train Loss: 0.34528 | Train Acc: 86.290\n",
      "\tEpoch 5 | Validation Loss: 0.3546120375394821 | Validation Acc: 85.200\n",
      "Epoch 006: | Train Loss: 0.34076 | Train Acc: 86.240\n",
      "\tEpoch 6 | Validation Loss: 0.35958221077919006 | Validation Acc: 84.400\n",
      "Epoch 007: | Train Loss: 0.34122 | Train Acc: 86.345\n",
      "\tEpoch 7 | Validation Loss: 0.35563632160425185 | Validation Acc: 84.860\n",
      "Epoch 008: | Train Loss: 0.33750 | Train Acc: 86.655\n",
      "\tEpoch 8 | Validation Loss: 0.36434072464704514 | Validation Acc: 84.280\n",
      "Epoch 009: | Train Loss: 0.33787 | Train Acc: 86.705\n",
      "\tEpoch 9 | Validation Loss: 0.36077595591545103 | Validation Acc: 84.840\n",
      "Epoch 010: | Train Loss: 0.33624 | Train Acc: 86.900\n",
      "\tEpoch 10 | Validation Loss: 0.3600035583972931 | Validation Acc: 84.500\n",
      "Epoch 011: | Train Loss: 0.33369 | Train Acc: 87.005\n",
      "\tEpoch 11 | Validation Loss: 0.35831941813230517 | Validation Acc: 84.520\n",
      "Epoch 012: | Train Loss: 0.33486 | Train Acc: 86.680\n",
      "\tEpoch 12 | Validation Loss: 0.35737200975418093 | Validation Acc: 84.380\n",
      "Epoch 013: | Train Loss: 0.33226 | Train Acc: 86.705\n",
      "\tEpoch 13 | Validation Loss: 0.35092742174863817 | Validation Acc: 85.100\n",
      "Epoch 014: | Train Loss: 0.33108 | Train Acc: 87.050\n",
      "\tEpoch 14 | Validation Loss: 0.35160699635744097 | Validation Acc: 84.820\n",
      "Epoch 015: | Train Loss: 0.33335 | Train Acc: 87.085\n",
      "\tEpoch 15 | Validation Loss: 0.35556463748216627 | Validation Acc: 84.640\n",
      "Epoch 016: | Train Loss: 0.33157 | Train Acc: 86.845\n",
      "\tEpoch 16 | Validation Loss: 0.35479399204254153 | Validation Acc: 85.080\n",
      "Epoch 017: | Train Loss: 0.32971 | Train Acc: 86.910\n",
      "\tEpoch 17 | Validation Loss: 0.3621010306477547 | Validation Acc: 84.240\n",
      "Epoch 018: | Train Loss: 0.33161 | Train Acc: 86.565\n",
      "\tEpoch 18 | Validation Loss: 0.3495055818557739 | Validation Acc: 84.760\n",
      "Epoch 019: | Train Loss: 0.32894 | Train Acc: 87.085\n",
      "\tEpoch 19 | Validation Loss: 0.3543664261698723 | Validation Acc: 84.740\n",
      "Epoch 020: | Train Loss: 0.32879 | Train Acc: 87.055\n",
      "\tEpoch 20 | Validation Loss: 0.3588589233160019 | Validation Acc: 84.600\n",
      "Epoch 021: | Train Loss: 0.33003 | Train Acc: 86.900\n",
      "\tEpoch 21 | Validation Loss: 0.35649503916502 | Validation Acc: 84.360\n",
      "Epoch 022: | Train Loss: 0.32957 | Train Acc: 86.885\n",
      "\tEpoch 22 | Validation Loss: 0.3520039227604866 | Validation Acc: 84.620\n",
      "Epoch 023: | Train Loss: 0.32824 | Train Acc: 86.950\n",
      "\tEpoch 23 | Validation Loss: 0.35997951626777647 | Validation Acc: 84.980\n",
      "Epoch 024: | Train Loss: 0.32992 | Train Acc: 86.545\n",
      "\tEpoch 24 | Validation Loss: 0.3578643098473549 | Validation Acc: 84.520\n",
      "Epoch 025: | Train Loss: 0.32883 | Train Acc: 86.690\n",
      "\tEpoch 25 | Validation Loss: 0.35663714349269865 | Validation Acc: 84.700\n",
      "Epoch 026: | Train Loss: 0.32901 | Train Acc: 86.735\n",
      "\tEpoch 26 | Validation Loss: 0.35319191455841065 | Validation Acc: 85.040\n",
      "Epoch 027: | Train Loss: 0.32842 | Train Acc: 86.735\n",
      "\tEpoch 27 | Validation Loss: 0.35251353979110717 | Validation Acc: 84.940\n",
      "Epoch 028: | Train Loss: 0.32904 | Train Acc: 86.740\n",
      "\tEpoch 28 | Validation Loss: 0.355698755979538 | Validation Acc: 84.580\n",
      "Epoch 029: | Train Loss: 0.32651 | Train Acc: 87.070\n",
      "\tEpoch 29 | Validation Loss: 0.3543186324834824 | Validation Acc: 84.880\n",
      "Epoch 030: | Train Loss: 0.32917 | Train Acc: 86.600\n",
      "\tEpoch 30 | Validation Loss: 0.3529640784859657 | Validation Acc: 85.300\n",
      "Epoch 031: | Train Loss: 0.32718 | Train Acc: 86.830\n",
      "\tEpoch 31 | Validation Loss: 0.35340858370065686 | Validation Acc: 85.240\n",
      "Epoch 032: | Train Loss: 0.32801 | Train Acc: 86.900\n",
      "\tEpoch 32 | Validation Loss: 0.34921552300453185 | Validation Acc: 85.180\n",
      "Epoch 033: | Train Loss: 0.32823 | Train Acc: 86.820\n",
      "\tEpoch 33 | Validation Loss: 0.35189654856920244 | Validation Acc: 85.140\n",
      "Epoch 034: | Train Loss: 0.32614 | Train Acc: 86.855\n",
      "\tEpoch 34 | Validation Loss: 0.3578176972270012 | Validation Acc: 84.560\n",
      "Epoch 035: | Train Loss: 0.32625 | Train Acc: 87.055\n",
      "\tEpoch 35 | Validation Loss: 0.35184350281953813 | Validation Acc: 84.820\n",
      "Epoch 036: | Train Loss: 0.32627 | Train Acc: 86.975\n",
      "\tEpoch 36 | Validation Loss: 0.350409529209137 | Validation Acc: 85.260\n",
      "Epoch 037: | Train Loss: 0.32635 | Train Acc: 86.820\n",
      "\tEpoch 37 | Validation Loss: 0.3524908721446991 | Validation Acc: 85.060\n",
      "Epoch 038: | Train Loss: 0.32624 | Train Acc: 87.300\n",
      "\tEpoch 38 | Validation Loss: 0.35627075403928754 | Validation Acc: 85.080\n",
      "Epoch 039: | Train Loss: 0.32579 | Train Acc: 86.940\n",
      "\tEpoch 39 | Validation Loss: 0.3538075494766235 | Validation Acc: 84.760\n",
      "Epoch 040: | Train Loss: 0.32669 | Train Acc: 87.105\n",
      "\tEpoch 40 | Validation Loss: 0.3519828099012375 | Validation Acc: 84.860\n",
      "Epoch 041: | Train Loss: 0.32498 | Train Acc: 87.175\n",
      "\tEpoch 41 | Validation Loss: 0.35000269949436186 | Validation Acc: 85.660\n",
      "Epoch 042: | Train Loss: 0.32626 | Train Acc: 87.040\n",
      "\tEpoch 42 | Validation Loss: 0.35408357173204424 | Validation Acc: 85.220\n",
      "Epoch 043: | Train Loss: 0.32480 | Train Acc: 87.120\n",
      "\tEpoch 43 | Validation Loss: 0.35274907886981965 | Validation Acc: 84.700\n",
      "Epoch 044: | Train Loss: 0.32615 | Train Acc: 87.030\n",
      "\tEpoch 44 | Validation Loss: 0.3529551526904106 | Validation Acc: 85.000\n",
      "Epoch 045: | Train Loss: 0.32492 | Train Acc: 86.945\n",
      "\tEpoch 45 | Validation Loss: 0.3502847942709923 | Validation Acc: 84.980\n",
      "Epoch 046: | Train Loss: 0.32574 | Train Acc: 87.060\n",
      "\tEpoch 46 | Validation Loss: 0.35325095653533933 | Validation Acc: 84.760\n",
      "Epoch 047: | Train Loss: 0.32558 | Train Acc: 87.130\n",
      "\tEpoch 47 | Validation Loss: 0.35042118936777117 | Validation Acc: 85.300\n",
      "Epoch 048: | Train Loss: 0.32524 | Train Acc: 87.065\n",
      "\tEpoch 48 | Validation Loss: 0.3579656356573105 | Validation Acc: 84.460\n",
      "Epoch 049: | Train Loss: 0.32524 | Train Acc: 86.910\n",
      "\tEpoch 49 | Validation Loss: 0.35260759711265566 | Validation Acc: 85.600\n",
      "Epoch 050: | Train Loss: 0.32552 | Train Acc: 87.030\n",
      "\tEpoch 50 | Validation Loss: 0.3521893846988678 | Validation Acc: 85.160\n",
      "Epoch 051: | Train Loss: 0.32542 | Train Acc: 86.970\n",
      "\tEpoch 51 | Validation Loss: 0.35110820323228836 | Validation Acc: 84.980\n",
      "Epoch 052: | Train Loss: 0.32351 | Train Acc: 87.085\n",
      "\tEpoch 52 | Validation Loss: 0.3535305374860764 | Validation Acc: 84.900\n",
      "Epoch 053: | Train Loss: 0.32344 | Train Acc: 87.145\n",
      "\tEpoch 53 | Validation Loss: 0.3526612889766693 | Validation Acc: 84.640\n",
      "Epoch 054: | Train Loss: 0.32412 | Train Acc: 87.050\n",
      "\tEpoch 54 | Validation Loss: 0.3510060539841652 | Validation Acc: 85.380\n",
      "Epoch 055: | Train Loss: 0.32548 | Train Acc: 87.120\n",
      "\tEpoch 55 | Validation Loss: 0.3510501140356064 | Validation Acc: 85.260\n",
      "Epoch 056: | Train Loss: 0.32360 | Train Acc: 86.980\n",
      "\tEpoch 56 | Validation Loss: 0.35067378610372546 | Validation Acc: 85.360\n",
      "Epoch 057: | Train Loss: 0.32347 | Train Acc: 87.260\n",
      "\tEpoch 57 | Validation Loss: 0.34558575809001923 | Validation Acc: 85.460\n",
      "Epoch 058: | Train Loss: 0.32482 | Train Acc: 87.100\n",
      "\tEpoch 58 | Validation Loss: 0.3458511635661125 | Validation Acc: 85.100\n",
      "Epoch 059: | Train Loss: 0.32420 | Train Acc: 87.125\n",
      "\tEpoch 59 | Validation Loss: 0.3504070070385933 | Validation Acc: 85.320\n",
      "Epoch 060: | Train Loss: 0.32327 | Train Acc: 87.230\n",
      "\tEpoch 60 | Validation Loss: 0.351272052526474 | Validation Acc: 85.400\n",
      "Epoch 061: | Train Loss: 0.32256 | Train Acc: 86.930\n",
      "\tEpoch 61 | Validation Loss: 0.3486678141355515 | Validation Acc: 85.100\n",
      "Epoch 062: | Train Loss: 0.32304 | Train Acc: 87.045\n",
      "\tEpoch 62 | Validation Loss: 0.35363181322813037 | Validation Acc: 84.660\n",
      "Epoch 063: | Train Loss: 0.32299 | Train Acc: 87.075\n",
      "\tEpoch 63 | Validation Loss: 0.3526637423038483 | Validation Acc: 85.220\n",
      "Epoch 064: | Train Loss: 0.32367 | Train Acc: 87.230\n",
      "\tEpoch 64 | Validation Loss: 0.34999871492385864 | Validation Acc: 85.440\n",
      "Epoch 065: | Train Loss: 0.32233 | Train Acc: 86.965\n",
      "\tEpoch 65 | Validation Loss: 0.35373323380947114 | Validation Acc: 85.280\n",
      "Epoch 066: | Train Loss: 0.32222 | Train Acc: 87.345\n",
      "\tEpoch 66 | Validation Loss: 0.3508892819285393 | Validation Acc: 85.520\n",
      "Epoch 067: | Train Loss: 0.32109 | Train Acc: 87.295\n",
      "\tEpoch 67 | Validation Loss: 0.3535212177038193 | Validation Acc: 84.140\n",
      "Epoch 068: | Train Loss: 0.32332 | Train Acc: 86.980\n",
      "\tEpoch 68 | Validation Loss: 0.3490945965051651 | Validation Acc: 84.780\n",
      "Epoch 069: | Train Loss: 0.32213 | Train Acc: 87.010\n",
      "\tEpoch 69 | Validation Loss: 0.3538569939136505 | Validation Acc: 85.140\n",
      "Epoch 070: | Train Loss: 0.32269 | Train Acc: 87.065\n",
      "\tEpoch 70 | Validation Loss: 0.355749340057373 | Validation Acc: 84.500\n",
      "Epoch 071: | Train Loss: 0.32177 | Train Acc: 87.480\n",
      "\tEpoch 71 | Validation Loss: 0.35603936165571215 | Validation Acc: 84.960\n",
      "Epoch 072: | Train Loss: 0.32219 | Train Acc: 87.070\n",
      "\tEpoch 72 | Validation Loss: 0.3549132809042931 | Validation Acc: 85.080\n",
      "Epoch 073: | Train Loss: 0.32223 | Train Acc: 87.045\n",
      "\tEpoch 73 | Validation Loss: 0.3483595535159111 | Validation Acc: 85.720\n",
      "Epoch 074: | Train Loss: 0.32294 | Train Acc: 86.915\n",
      "\tEpoch 74 | Validation Loss: 0.35249575078487394 | Validation Acc: 85.460\n",
      "Epoch 075: | Train Loss: 0.32223 | Train Acc: 87.110\n",
      "\tEpoch 75 | Validation Loss: 0.35018482655286787 | Validation Acc: 85.440\n",
      "Epoch 076: | Train Loss: 0.32151 | Train Acc: 87.045\n",
      "\tEpoch 76 | Validation Loss: 0.3476392322778702 | Validation Acc: 85.740\n",
      "Epoch 077: | Train Loss: 0.32191 | Train Acc: 87.095\n",
      "\tEpoch 77 | Validation Loss: 0.3471900629997253 | Validation Acc: 85.120\n",
      "Epoch 078: | Train Loss: 0.32169 | Train Acc: 87.370\n",
      "\tEpoch 78 | Validation Loss: 0.35969123616814613 | Validation Acc: 85.020\n",
      "Epoch 079: | Train Loss: 0.32085 | Train Acc: 87.125\n",
      "\tEpoch 79 | Validation Loss: 0.3504809150099754 | Validation Acc: 85.500\n",
      "Epoch 080: | Train Loss: 0.32231 | Train Acc: 86.950\n",
      "\tEpoch 80 | Validation Loss: 0.35357960671186445 | Validation Acc: 85.100\n",
      "Epoch 081: | Train Loss: 0.32321 | Train Acc: 87.140\n",
      "\tEpoch 81 | Validation Loss: 0.35020321190357206 | Validation Acc: 85.400\n",
      "Epoch 082: | Train Loss: 0.32158 | Train Acc: 87.190\n",
      "\tEpoch 82 | Validation Loss: 0.35388936966657636 | Validation Acc: 85.140\n",
      "Epoch 083: | Train Loss: 0.32189 | Train Acc: 86.785\n",
      "\tEpoch 83 | Validation Loss: 0.3525266572833061 | Validation Acc: 84.960\n",
      "Epoch 084: | Train Loss: 0.31968 | Train Acc: 87.215\n",
      "\tEpoch 84 | Validation Loss: 0.3506897503137589 | Validation Acc: 85.140\n",
      "Epoch 085: | Train Loss: 0.32119 | Train Acc: 86.960\n",
      "\tEpoch 85 | Validation Loss: 0.35140283316373827 | Validation Acc: 85.000\n",
      "Epoch 086: | Train Loss: 0.32090 | Train Acc: 87.040\n",
      "\tEpoch 86 | Validation Loss: 0.3517202581465244 | Validation Acc: 84.680\n",
      "Epoch 087: | Train Loss: 0.32056 | Train Acc: 87.105\n",
      "\tEpoch 87 | Validation Loss: 0.3484680613875389 | Validation Acc: 85.100\n",
      "Epoch 088: | Train Loss: 0.32052 | Train Acc: 87.275\n",
      "\tEpoch 88 | Validation Loss: 0.3527704295516014 | Validation Acc: 85.140\n",
      "Epoch 089: | Train Loss: 0.31924 | Train Acc: 87.075\n",
      "\tEpoch 89 | Validation Loss: 0.3502177873253822 | Validation Acc: 85.560\n",
      "Epoch 090: | Train Loss: 0.31973 | Train Acc: 87.245\n",
      "\tEpoch 90 | Validation Loss: 0.35643703520298003 | Validation Acc: 85.600\n",
      "Epoch 091: | Train Loss: 0.31979 | Train Acc: 87.220\n",
      "\tEpoch 91 | Validation Loss: 0.3481185883283615 | Validation Acc: 85.440\n",
      "Epoch 092: | Train Loss: 0.32037 | Train Acc: 87.130\n",
      "\tEpoch 92 | Validation Loss: 0.3535824969410896 | Validation Acc: 84.980\n",
      "Epoch 093: | Train Loss: 0.31916 | Train Acc: 87.190\n",
      "\tEpoch 93 | Validation Loss: 0.34728955090045927 | Validation Acc: 85.980\n",
      "Epoch 094: | Train Loss: 0.31997 | Train Acc: 87.450\n",
      "\tEpoch 94 | Validation Loss: 0.3539603859186172 | Validation Acc: 85.660\n",
      "Epoch 095: | Train Loss: 0.32143 | Train Acc: 87.030\n",
      "\tEpoch 95 | Validation Loss: 0.3538158079981804 | Validation Acc: 85.220\n",
      "Epoch 096: | Train Loss: 0.31948 | Train Acc: 87.265\n",
      "\tEpoch 96 | Validation Loss: 0.3509560739994049 | Validation Acc: 85.060\n",
      "Epoch 097: | Train Loss: 0.32100 | Train Acc: 86.980\n",
      "\tEpoch 97 | Validation Loss: 0.3469493219256401 | Validation Acc: 85.640\n",
      "Epoch 098: | Train Loss: 0.32082 | Train Acc: 87.185\n",
      "\tEpoch 98 | Validation Loss: 0.35153563469648363 | Validation Acc: 85.200\n",
      "Epoch 099: | Train Loss: 0.31890 | Train Acc: 87.300\n",
      "\tEpoch 99 | Validation Loss: 0.35815087765455245 | Validation Acc: 85.300\n",
      "Epoch 100: | Train Loss: 0.32045 | Train Acc: 87.140\n",
      "\tEpoch 100 | Validation Loss: 0.35779536962509156 | Validation Acc: 86.060\n"
     ]
    }
   ],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # go through all the batches generated by dataloader\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute the model output\n",
    "        yhat = model(inputs)\n",
    "        targets = torch.reshape(targets, (-1, 1))\n",
    "        # print(yhat.shape, targets.shape)\n",
    "        # calculate loss\n",
    "        loss = criterion(yhat, targets)\n",
    "        acc = binary_acc(yhat, targets)\n",
    "        # credit assignment\n",
    "        loss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1:03}: | Train Loss: {epoch_loss/len(train_dl):.5f} | Train Acc: {epoch_acc/len(train_dl):.3f}', end=\"\\n\\t\")\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for inputs, targets in validation_dl:\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        \n",
    "        yhat = model(inputs)\n",
    "        loss = criterion(yhat, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        acc = binary_acc(yhat, targets)\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1} | Validation Loss: {epoch_loss / len(validation_dl)} | Validation Acc: {epoch_acc/len(validation_dl):.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d001001",
   "metadata": {},
   "source": [
    "## Eval Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_dl:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54e0a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65df16ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91      1585\n",
      "         1.0       0.75      0.43      0.55       415\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.81      0.70      0.73      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789d783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
